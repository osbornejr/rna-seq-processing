shell.executable
("/bin/bash")
#Load in config options, and make sure they are as expected
configfile: "config.yaml" 
input_path=os.path.join(config["path_to_files"], '') #make sure slash is at end of path
run_name=os.path.basename(os.path.normpath(input_path)) #get name of job from last directory name 
workdir:"results/"+run_name #make sandbox for run
basedir=os.getcwd()+'/' #set basedir for jobs run using specific job directory
flowdir=workflow.basedir+"/"
#TODO put long shell commands into scripts and source?

wildcard_constraints: 
	sample = '|'.join(config["samples"]) 
include: "rules/"+config["assembly_method"]+"-assembly.smk"
#include: "rules/transcript-classification.smk"
bat=5
rule all:
	input:	
		#'rnasamba/non-code-hits.list',
		#'rnasamba/code-hits.list',
		expand('output-data/{read_type}/{sample}_RSEM.{read_type}.results',sample=config["samples"],read_type=["isoforms","genes"])
	
rule clean:
# all in one cleaning of fastq files with fastp. Could alternatively do this with trimmomatic? But need specific adapter sequences etc. TODO double check quality independently after running fastp with fastqc
	input:
		r1=input_path+"raw-reads/{sample}/{sample}_read_1.fastq.gz",
		r2=input_path+"raw-reads/{sample}/{sample}_read_2.fastq.gz"
	output: 
		r1=basedir+"clean-reads/{sample}/{sample}_read_1_fastp.fastq.gz",
		r2=basedir+"clean-reads/{sample}/{sample}_read_2_fastp.fastq.gz",
		html=basedir+"reports/{sample}/{sample}_fastp.html",
		json=basedir+"reports/{sample}/{sample}_fastp.json"
		#other fastp outputs?
		# threads?
	shell: 
		'fastp '
		'-i {input.r1} -I {input.r2} '
		'-o {output.r1} -O {output.r2} '
		'-h {output.html} -j {output.json} '
		'-w {threads} '

